{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah2OcTTsCRSH",
        "outputId": "b677373c-1876-4907-f808-45d60525c545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.18.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.23.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=e628735fd8a40bf6b3d1cd2b15c09ab9328233346f373879670989f38abf1d50\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=875035c2f21ab8b66944e1b9c612fd87e48d42d912613af8c975f6f7461dd3ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCK23q6LSM_z",
        "outputId": "69c1a4ae-9536-40ef-cc0e-c1d50928a263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from segmentation_models_pytorch import UnetPlusPlus\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from sklearn.metrics import jaccard_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4xUIv9jCUnM",
        "outputId": "902a6e60-83dd-4489-a27c-3f6cf0678518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch [1/10], Loss: 0.0825, IoU: 0.9167\n",
            "Epoch [2/10], Loss: 0.0115, IoU: 1.0000\n",
            "Epoch [3/10], Loss: 0.0080, IoU: 1.0000\n",
            "Epoch [4/10], Loss: 0.0070, IoU: 1.0000\n",
            "Epoch [5/10], Loss: 0.0066, IoU: 1.0000\n",
            "Epoch [6/10], Loss: 0.0064, IoU: 1.0000\n",
            "Epoch [7/10], Loss: 0.0063, IoU: 1.0000\n",
            "Epoch [8/10], Loss: 0.0063, IoU: 1.0000\n",
            "Epoch [9/10], Loss: 0.0063, IoU: 1.0000\n",
            "Epoch [10/10], Loss: 0.0062, IoU: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Hàm tính IoU\n",
        "def calculate_iou(pred_mask, true_mask):\n",
        "    pred_mask = pred_mask.cpu().numpy().astype(np.uint8)\n",
        "    true_mask = true_mask.cpu().numpy().astype(np.uint8)\n",
        "    intersection = np.sum(pred_mask * true_mask)\n",
        "    union = np.sum(pred_mask) + np.sum(true_mask) - intersection\n",
        "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "    return iou\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_folder, mask_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.mask_folder = mask_folder\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_list = os.listdir(image_folder)\n",
        "        self.mask_list = os.listdir(mask_folder)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder, self.image_list[idx])\n",
        "        mask_path = os.path.join(self.mask_folder, self.mask_list[idx])\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        _, image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        _, mask = cv2.threshold(mask, 0, 1, cv2.THRESH_BINARY)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        image = transforms.ToTensor()(image)\n",
        "        mask = transforms.ToTensor()(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Đường dẫn đến thư mục chứa ảnh và mask\n",
        "train_image_path = r'/content/drive/MyDrive/images'\n",
        "mask_image_path = r'/content/drive/MyDrive/masks'\n",
        "\n",
        "# Định nghĩa các phép augmentation\n",
        "transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(image_folder=train_image_path, mask_folder=mask_image_path, transform=transform)\n",
        "\n",
        "# DataLoader để tải dữ liệu theo batch\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Chọn mô hình\n",
        "model = UnetPlusPlus(encoder_name=\"resnet101\", encoder_weights=\"imagenet\", in_channels=3, classes=1).to(device)\n",
        "\n",
        "# Chọn hàm mất mát và tối ưu hóa\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_iou = 0\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Tính IoU\n",
        "        outputs_thresholded = (outputs > 0.5).float()\n",
        "        iou = calculate_iou(outputs_thresholded, masks)\n",
        "        epoch_iou += iou\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}, IoU: {epoch_iou/len(train_loader):.4f}\")\n",
        "\n",
        "# Lưu mô hình đã huấn luyện\n",
        "torch.save(model.state_dict(), \"unetplusplus_model.pth\")\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_list = os.listdir(image_folder)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder, self.image_list[idx])\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        _, image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        image = transforms.ToTensor()(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Đường dẫn đến thư mục chứa ảnh mới (không có mask)\n",
        "new_images_path = r'/content/drive/MyDrive/test'\n",
        "\n",
        "# Tạo một TestDataset cho dữ liệu mới\n",
        "test_dataset = TestDataset(image_folder=new_images_path, transform=A.Resize(256, 256))\n",
        "\n",
        "# DataLoader để tải dữ liệu mới theo batch\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Chạy dự đoán trên dữ liệu mới\n",
        "model.eval()  # Chuyển sang chế độ đánh giá (không cần tính gradient)\n",
        "\n",
        "# Lặp qua các ảnh dự đoán và tạo contour\n",
        "for i, new_images in enumerate(test_loader):\n",
        "    outputs = model(new_images.to(device))  # Move input data to GPU\n",
        "\n",
        "    for j in range(outputs.shape[0]):\n",
        "        predicted_mask = outputs[j, 0].detach().cpu().numpy()\n",
        "\n",
        "        # Chuyển đổi ảnh binary sang ảnh grayscale\n",
        "        _, binary_mask = cv2.threshold(predicted_mask, 0.5, 1, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Áp dụng morphological opening để loại bỏ nhiễu\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        # Trích xuất contour từ ảnh binary\n",
        "        contours, _ = cv2.findContours(np.uint8(binary_mask), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Lọc các contour dựa trên diện tích\n",
        "        min_area = 50  # Điều chỉnh giá trị này tùy thuộc vào kích thước tế bào\n",
        "        filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
        "\n",
        "        # Tạo một bản sao của ảnh gốc để vẽ contour lên đó\n",
        "        original_image_copy = np.transpose(new_images[j].numpy(), (1, 2, 0)).copy()\n",
        "\n",
        "        # Vẽ contour đã lọc trên bản sao của ảnh gốc\n",
        "        cv2.drawContours(original_image_copy, filtered_contours, -1, (0, 255, 0), 1)\n",
        "\n",
        "        # Lưu ảnh chứa contour\n",
        "        output_filename = f\"output_image_{i * batch_size + j}.jpg\"\n",
        "        cv2.imwrite(output_filename, original_image_copy)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
